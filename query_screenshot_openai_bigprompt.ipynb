{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query screenshots using OpenAI GPT-4o-mini\n",
    "\n",
    "The image descriptions were created using OpenAI as well (script `generate_image_descriptions.py`). This will send all the descriptions to OpenAI and ask for the images that are most related to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the system prompt for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOP_IMAGES = 12\n",
    "N_IMAGES = 400\n",
    "IMAGE_DIR = \"../data/my_screenshots/\"\n",
    "\n",
    "initial_context = \"\"\"\n",
    "Your job is to find the top {N_TOP_IMAGES} best screenshots based on a query and the image descriptions. \n",
    "\n",
    "Bellow there a bunch of image descriptors preceded by their filename. Make sure that, in your answer\n",
    "you only include the image filenames in order from most relevant to least relevant from the chosen {N_TOP_IMAGES}.\n",
    "\n",
    "Example, given a query like this:\n",
    "\n",
    "\"Which screenshots appear to be tech products?\"\"\n",
    "\n",
    "You should answer like, without text before this and without numbers before the image names (THIS IS AN FORMAT EXAMPLE, THESE IMAGES DON'T EXISTS ):\n",
    "IMAGE_01.PNG\n",
    "IMAGE_02.jpeg\n",
    "...\n",
    "\n",
    "First there is a list of image filenames, only answer with these filenames in the order of relevance:\n",
    "\n",
    "{image_filenames}\n",
    "\n",
    "The following is a list of image descriptor (one for each image), you should use these to answer the query.\n",
    "\n",
    "{image_descriptors}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "images_files = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) \n",
    "                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "random.shuffle(images_files)\n",
    "\n",
    "print(\"Total number of images: \", len(images_files))\n",
    "print(\"Liminting to \", N_IMAGES)\n",
    "\n",
    "image_list_context = \"\"\n",
    "descriptions_context = \"\"\n",
    "for img in images_files[:N_IMAGES]: # limit to not exceed no tokens\n",
    "    if os.path.exists(f\"{img}.txt\"):\n",
    "        with open(f\"{img}.txt\" , \"r\") as f:\n",
    "            image_list_context += f\"{os.path.basename(img)}\\n\"\n",
    "            descriptions_context += f\"\\n\\n{os.path.basename(img)}:\\n\"\n",
    "            descriptions_context += f.read()\n",
    "\n",
    "initial_context = initial_context.format(N_TOP_IMAGES=N_TOP_IMAGES, \n",
    "                                            image_filenames=image_list_context, image_descriptors=descriptions_context)\n",
    "print(initial_context)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_wrapper import LLM_Wrapper, LLM_Models\n",
    "\n",
    "llm_wrapper = LLM_Wrapper(LLM_Models.OPENAI_GPT4_MINI, temperature=0.2)\n",
    "llm_wrapper.send_message(initial_context, role=\"system\")\n",
    "print(\"Set initial context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_notebook, show\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "from utils import image_and_descriptions_plot\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "N_COLUMNS = 4\n",
    "N_ROWS = 3\n",
    "\n",
    "text_input = widgets.Text(value='Which screenshots show 3d printing models?', \n",
    "                          placeholder='Enter text...', description='Filter text:', \n",
    "    disabled=False, style={'description_width': 'initial'}, layout=widgets.Layout(width='100%', height='40px'))\n",
    "\n",
    "filter_button = widgets.Button(description='Filter it', button_style='success')\n",
    "\n",
    "widgets_box = VBox([text_input, filter_button])\n",
    "\n",
    "display(widgets_box)\n",
    "\n",
    "\n",
    "\n",
    "def on_button_click(b):\n",
    "    clear_output(wait=True)\n",
    "    display(widgets_box)\n",
    "    \n",
    "    q_str = \"Query: \"+text_input.value\n",
    "    assistant_res = llm_wrapper.send_message(q_str, role=\"user\")\n",
    "    \n",
    "    images_retrieved = assistant_res.split(\"\\n\")\n",
    "    image_paths = []\n",
    "    for img in images_retrieved:\n",
    "        img_path = os.path.join(IMAGE_DIR, img).strip()\n",
    "        if os.path.exists(img_path):\n",
    "            image_paths.append(img_path)\n",
    "        else:\n",
    "            print(f\"Image {img} not found\")\n",
    "    # images_paths = [os.path.join(IMAGE_DIR, img) for img in images_retrieved]\n",
    "    p = image_and_descriptions_plot(image_paths, N_COLUMNS, N_ROWS)\n",
    "    show(p)\n",
    "\n",
    "filter_button.on_click(on_button_click)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".screenshot_query",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
