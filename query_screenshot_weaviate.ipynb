{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query screenshots using SBERT/OPENAI\n",
    "\n",
    "The image descriptions were created using OpenAI (script `generate_image_descriptions.py`).\n",
    "\n",
    "Embeddings may being created using SBERT (`create_weaviate_database_sbert.py`) or text-embedding-3-* from OpenAI (`create_weaviate_database_openai.py`).\n",
    "\n",
    "Those embeddings are fed to an weviate database, and are retrieved using near_vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define which embedding will be (was) used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/Users/gustavofuhr/projects/data/my_screenshots/\"\n",
    "EMBEDDER = \"OPENAI\" # SBERT or OPENAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Call python script that will populate weaviate database\n",
    "\n",
    "Should not take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDER == \"OPENAI\":\n",
    "    !python create_weaviate_database_openai.py --image_dir {IMAGE_DIR}\n",
    "elif EMBEDDER == \"SBERT\":\n",
    "    !python create_weaviate_database_sbert.py --image_dir {IMAGE_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "WEAVIATE_URL = \"http://localhost:8080\"\n",
    "class_name = \"ScreenshotQuerySBERT\" if EMBEDDER == \"SBERT\" else \"ScreenshotQueryOPENAI\"\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "classes = list(client.collections.list_all().keys())\n",
    "if not any(cls == class_name for cls in classes):\n",
    "    raise Exception(f\"Class {class_name} not found in schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define embedding function for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def embed_query(query_str):\n",
    "    raise NotImplementedError(\"Embedder is not set\")\n",
    "\n",
    "if EMBEDDER == \"SBERT\":\n",
    "    # define functions to generate embedding from query str\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    SBERT_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "    model = SentenceTransformer(SBERT_MODEL)\n",
    "    def embed_query(query_str):\n",
    "        return model.encode(query_str).tolist()\n",
    "    \n",
    "elif EMBEDDER == \"OPENAI\":\n",
    "    from create_descriptions_openai_embeddings import get_openai_embedding\n",
    "    def embed_query(query_str):\n",
    "        return get_openai_embedding(query_str)\n",
    "    \n",
    "def query_screenshots(query_str, distance = 0.7, n_images_limit = 5):\n",
    "\n",
    "    q_feat = embed_query(query_str)\n",
    "\n",
    "    collection = client.collections.get(class_name)\n",
    "\n",
    "    response = collection.query.near_vector(\n",
    "        near_vector=q_feat,\n",
    "        distance=distance,\n",
    "        limit=n_images_limit,\n",
    "    )\n",
    "\n",
    "    return [os.path.join(IMAGE_DIR, o.properties[\"filename\"]) for o in response.objects]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, create the interface for querying and query screenshots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_notebook, show\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "from utils import image_and_descriptions_plot\n",
    "\n",
    "N_COLUMNS = 4\n",
    "N_ROWS = 3\n",
    "\n",
    "distance_slider = widgets.FloatSlider(value=0.7, min=0, max=1.0, step=0.01, \n",
    "    description='Distance:', continuous_update=False, style={'description_width': 'initial'}, \n",
    "    layout=widgets.Layout(width='50%'))\n",
    "\n",
    "n_images_slider = widgets.IntSlider(value=12, min=0, max=50, step=1, \n",
    "    description='n_images:', continuous_update=False, style={'description_width': 'initial'}, \n",
    "    layout=widgets.Layout(width='50%'))\n",
    "\n",
    "text_input = widgets.Text(value='Which screenshots show dogs?', \n",
    "                          placeholder='Enter text...', description='Filter text:', \n",
    "    disabled=False, style={'description_width': 'initial'}, layout=widgets.Layout(width='100%', height='40px'))\n",
    "\n",
    "filter_button = widgets.Button(description='Filter it', button_style='success')\n",
    "\n",
    "sliders_box = HBox([distance_slider, n_images_slider])\n",
    "widgets_box = VBox([sliders_box, text_input, filter_button])\n",
    "\n",
    "display(widgets_box)\n",
    "\n",
    "\n",
    "\n",
    "def on_button_click(b):\n",
    "    clear_output(wait=True)\n",
    "    display(widgets_box)\n",
    "    print(f\"Distance: {distance_slider.value}, Number of images: {n_images_slider.value}, Filter Text: {text_input.value}\")\n",
    "    \n",
    "    images_retrieved = query_screenshots(text_input.value, distance = distance_slider.value, n_images_limit = n_images_slider.value)\n",
    "    p = image_and_descriptions_plot(images_retrieved, N_COLUMNS, N_ROWS)\n",
    "    show(p)\n",
    "    \n",
    "\n",
    "filter_button.on_click(on_button_click)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
